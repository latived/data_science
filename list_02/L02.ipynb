{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cite 2 técnicas para remoção de ruídos e, para cada uma, mostre uma vantagem e uma desvantagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binning \n",
    "- Análise de outliers\n",
    "\n",
    "Na primeira você tem a vantagem de diminuir a escala dos dados, isto é, facilitar sua análise a partir da redução (compactação) dos dados disponíveis; também pode ajudar na sua visualização e interpretação, bem como na identificação de outliers (dados extremos, possivelmente fora de algum intervalo pré-determinado). Um problema decorrente dessa prática é a possível perda de informações; reduz-se o ruído, mas também o sinal. \n",
    "\n",
    "Na segunda técnica, após feita a análise e identificaçãode outliers, o resultado final do modelo pode ser melhor: agora não há amostras extremas que enviesem sua performance (i.e., avaliação de créditos com outliers). Por outro lado, caso o conjunto de dados seja muito pequeno, a remoção de outliers pode prejudicar a performance do modelo construído. Além disso, é preciso cuidado na análise desses valores atípicos; por conta de suposições de normalidade, muitas vezes se confunde um valor raro (e talvez extremo, comum em distribuições *fat-tailed*) com *outliers* (geralmente decorrentes de erros na aquisição dos dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Qual é a importância de utilizar as seguintes abordagens de redução de dados no contexto de Ciência de Dados?\n",
    "\n",
    "\n",
    "- Redução de dimensionalidade\n",
    "- Redução de numerosidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São duas técnicas que ajudam na diminuição do tempo de aprendizado do modelo, bem como o tornam menos complexo e melhor interpretável. A redução de dimensionalidade ataca o problema da *maldição da dimensionalidade*, cujo principal aspecto é um alto número de atributos presente no conjunto de dados; atributos que, geralmente, não agregam valor ao modelo e muitas vezes vão na via contrária, que é aumentar o ruído do conjunto. Já a redução dos dados visa, como observado, obter um modelo suficientemente bom com menos amostras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. De que forma pode-se detectar o _overfitting_ em um classificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparando a performance do classificador no conjunto de validação e teste.\n",
    "- Comparando as curvas de aprendizado nos conjuntos de treino e validação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Em quais tipos de problemas é preferível utilizar _leave-one-out_ a utilizar _K-fold cross-validation_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nos casos onde o conjunto de dados é muito pequeno.\n",
    "- A dispensa da aleatoriedade na construção do conjunto de treino pode ajudar na confiabilidade do modelo (dado que o *viés* é menor se comparado a outras formas de validação)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Crie um _script_ em Python que avalie a diferença de desempenho entre os classificadores **K-NN** e **Naive Bayes** para o conjunto de dados _iris_ (`sklearn.datasets.load_iris`). Use _F-measure_ e _K-fold cross-validation_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9803921568627452\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(knn_clf, data, target, cv=3, scoring='f1_micro')  # por que f1_micro?\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9342320261437909\n"
     ]
    }
   ],
   "source": [
    "gnb_clf = GaussianNB()\n",
    "scores = cross_val_score(gnb_clf, data, target, cv=3, scoring='f1_micro')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note que usei `scoring`='f1_micro', o que significante que a métrica $F_1$ foi calculada a partir do total global de **True Positives (TP)**, **False Negatives (FN)** e **False Positives (FP)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No caso do 'f1_macro', temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9803411095077763\n",
      "0.9341061666330485\n"
     ]
    }
   ],
   "source": [
    "scores_knn = cross_val_score(knn_clf, data, target, cv=3, scoring='f1_macro')  # por que f1_micro?\n",
    "scores_gnb = cross_val_score(gnb_clf, data, target, cv=3, scoring='f1_macro')\n",
    "\n",
    "print(scores_knn.mean())\n",
    "print(scores_gnb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E para 'f1_weighted', que ajusta a falta de balançeamento entre as classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9803411095077762\n",
      "0.9341061666330485\n"
     ]
    }
   ],
   "source": [
    "scores_knn = cross_val_score(knn_clf, data, target, cv=3, scoring='f1_weighted')  # por que f1_micro?\n",
    "scores_gnb = cross_val_score(gnb_clf, data, target, cv=3, scoring='f1_weighted')\n",
    "\n",
    "print(scores_knn.mean())\n",
    "print(scores_gnb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Não mudou. Pode ter sido porque as classes já são balanceadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
